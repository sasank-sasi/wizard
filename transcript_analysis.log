2025-02-24 15:13:41,904 - ERROR - Fatal error: name '__file__' is not defined
2025-02-24 15:15:06,294 - INFO - Processing transcript and saving to: /Users/sasanksasi/Downloads/project/wizard/output/transcript_analysis_20250224_151506.json
2025-02-24 15:15:06,295 - INFO - Sending request to Groq API
2025-02-24 15:15:07,028 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-24 15:15:07,038 - INFO - Analysis saved to: /Users/sasanksasi/Downloads/project/wizard/output/transcript_analysis_20250224_151506.json
2025-02-24 15:15:07,038 - INFO - Analysis completed successfully
2025-02-24 15:18:41,962 - INFO - Processing transcript and saving to: /Users/sasanksasi/Downloads/project/wizard/output/transcript_analysis_20250224_151841.json
2025-02-24 15:18:41,963 - INFO - Sending request to Groq API
2025-02-24 15:18:42,455 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-24 15:18:42,463 - INFO - Analysis saved to: /Users/sasanksasi/Downloads/project/wizard/output/transcript_analysis_20250224_151841.json
2025-02-24 15:18:42,463 - INFO - Analysis completed successfully
2025-03-17 14:18:09,673 - INFO - Processing transcript and saving to: /Users/sasanksasi/Downloads/project/wizard/output/transcript_analysis_20250317_141809.json
2025-03-17 14:18:09,674 - ERROR - Fatal error: name 'transcript' is not defined
2025-03-17 14:32:00,366 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-03-17 14:32:00,366 - INFO - [33mPress CTRL+C to quit[0m
2025-03-17 14:32:00,367 - INFO -  * Restarting with stat
2025-03-17 14:32:05,320 - WARNING -  * Debugger is active!
2025-03-17 14:32:05,332 - INFO -  * Debugger PIN: 491-071-532
2025-03-17 14:34:18,730 - INFO - 127.0.0.1 - - [17/Mar/2025 14:34:18] "[33mGET / HTTP/1.1[0m" 404 -
2025-03-17 14:34:18,975 - INFO - 127.0.0.1 - - [17/Mar/2025 14:34:18] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-03-17 14:34:34,325 - INFO - 127.0.0.1 - - [17/Mar/2025 14:34:34] "[31m[1mGET /analyze-audio HTTP/1.1[0m" 405 -
2025-03-17 14:37:05,312 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-03-17 14:37:05,312 - INFO - [33mPress CTRL+C to quit[0m
2025-03-17 14:37:05,313 - INFO -  * Restarting with stat
2025-03-17 14:37:10,570 - WARNING -  * Debugger is active!
2025-03-17 14:37:10,591 - INFO -  * Debugger PIN: 491-071-532
2025-03-17 14:39:50,548 - INFO -  * Detected change in '/Users/sasanksasi/Downloads/project/wizard/test.py', reloading
2025-03-17 14:39:51,185 - INFO -  * Restarting with stat
2025-03-17 14:39:56,723 - WARNING -  * Debugger is active!
2025-03-17 14:39:56,733 - INFO -  * Debugger PIN: 491-071-532
2025-03-17 14:43:05,149 - INFO -  * Detected change in '/Users/sasanksasi/Downloads/project/wizard/app.py', reloading
2025-03-17 14:43:05,678 - INFO -  * Restarting with stat
2025-03-17 14:43:11,105 - WARNING -  * Debugger is active!
2025-03-17 14:43:11,119 - INFO -  * Debugger PIN: 491-071-532
2025-03-17 14:43:31,477 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-03-17 14:43:31,477 - INFO - [33mPress CTRL+C to quit[0m
2025-03-17 14:43:31,478 - INFO -  * Restarting with stat
2025-03-17 14:43:38,499 - WARNING -  * Debugger is active!
2025-03-17 14:43:38,510 - INFO -  * Debugger PIN: 491-071-532
2025-03-17 15:06:41,908 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-24 15:12:27,775 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-25 01:56:03,082 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-25 02:07:27,596 - WARNING - Error while downloading from https://cdn-lfs-us-1.hf.co/repos/75/9f/759fc969b3b76eb86aaf241244bcc4172d9fc1cf017a3595b0be65895ff7fa89/a8e94b85976e5864ba3e9525c7e6c83b2a1eca42d4b797a0c7c24d778e40fd95?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1742852014&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0Mjg1MjAxNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzc1LzlmLzc1OWZjOTY5YjNiNzZlYjg2YWFmMjQxMjQ0YmNjNDE3MmQ5ZmMxY2YwMTdhMzU5NWIwYmU2NTg5NWZmN2ZhODkvYThlOTRiODU5NzZlNTg2NGJhM2U5NTI1YzdlNmM4M2IyYTFlY2E0MmQ0Yjc5N2EwYzdjMjRkNzc4ZTQwZmQ5NT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=AtRg2lONIo8bfMcKEQZDHIdTXfcFdcMkNRiYBzev-zHGbl1sh3zrGMlF1cLnkwtGVGgkfWrGtxZJmZpyVbZ9MVGfkGx48FzEskpOynroCHLSm1ieCKwkZZGbKslh47fJbQR-pgHIwxTKlRNSbJ7LG1%7EtP5IC8KogYqVPICduX3GXhCvyvXeZB4GqbASIB%7Eky5ZSFiOfh24VIKQAyNN5xqfqj1Wfgu9z-cXqoqY2F-R2MCEWr9ov7UzcvuBBg7HEIAdAef0JwhP8MIMo9nqOoy3p7NWqlr%7EkRZ7Qz624MNEAt14CBBkKmh-Rrzjac8LtiWgqfg38646E60nrCwhpl7Q__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
Trying to resume download...
2025-03-25 02:14:38,318 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_0.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,332 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_1.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,345 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_2.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,358 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_3.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,370 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_4.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,382 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_5.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,394 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_6.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,407 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_7.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,419 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_8.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,432 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_9.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,444 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_10.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,457 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_11.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,469 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_12.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,480 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_13.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,492 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_14.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,503 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_15.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,514 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_16.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,526 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_17.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,538 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_18.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,549 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_19.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,560 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_20.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,571 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_21.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,583 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_22.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,594 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_23.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,605 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_24.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,616 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_25.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,628 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_26.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,639 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_27.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,650 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_28.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,661 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_29.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,672 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_30.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,685 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_31.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,696 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_32.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,707 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_33.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,719 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_34.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,730 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_35.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,742 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_36.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,753 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_37.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,764 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_38.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,775 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_39.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,786 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_40.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,797 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_41.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,808 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_42.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,819 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_43.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,830 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_44.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,841 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_45.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,853 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_46.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,863 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_47.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,875 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_48.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,887 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_49.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,898 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_50.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,909 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_51.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,920 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_52.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,931 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_53.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,942 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_54.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,953 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_55.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,964 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_56.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,975 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_57.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,987 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_58.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:38,998 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_59.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:39,009 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_60.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:39,020 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_61.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:39,032 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_62.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:39,036 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp0gj0s9jy/chunk_63.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:14:39,042 - INFO - Transcription completed: 0 characters
2025-03-25 02:14:39,779 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-25 02:14:39,791 - ERROR - Analysis error: Expecting value: line 1 column 1 (char 0)
2025-03-25 02:18:34,523 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_0.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,542 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_1.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,562 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_2.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,577 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_3.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,594 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_4.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,610 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_5.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,627 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_6.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,648 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_7.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,669 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_8.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,689 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_9.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,707 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_10.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,725 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_11.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,743 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_12.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,759 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_13.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,774 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_14.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,790 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_15.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,809 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_16.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,827 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_17.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,843 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_18.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,857 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_19.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,871 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_20.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,886 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_21.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,899 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_22.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,912 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_23.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,927 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_24.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,941 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_25.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,955 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_26.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,968 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_27.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,982 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_28.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:34,993 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_29.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,005 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_30.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,017 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_31.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,029 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_32.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,042 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_33.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,057 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_34.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,071 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_35.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,082 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_36.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,095 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_37.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,106 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_38.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,117 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_39.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,128 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_40.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,140 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_41.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,153 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_42.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,164 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_43.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,177 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_44.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,188 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_45.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,199 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_46.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,210 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_47.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,221 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_48.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,233 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_49.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,244 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_50.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,256 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_51.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,266 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_52.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,278 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_53.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,289 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_54.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,300 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_55.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,311 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_56.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,323 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_57.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,334 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_58.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,345 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_59.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,356 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_60.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,368 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_61.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,380 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_62.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,385 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmp2c62px3t/chunk_63.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:18:35,391 - INFO - Transcription completed: 0 characters
2025-03-25 02:18:36,183 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-25 02:18:36,199 - ERROR - JSON parsing error: Expecting value: line 1 column 1 (char 0)
Response: Here is the analysis in JSON format:

{
    "transcript": "",
    "summary": "Summary of the meeting: Discussion on project timeline and milestones.",
    "key_points": [
        "Project timeline and milestones were discussed.",
        "The team needs to work on the project plan by the end of the week.",
        "The project manager will send out a reminder email to the team."
    ],
    "dates": [
        "End of the week"
    ],
    "emails": [
        "The project manager will send out a reminder email to the team."
    ],
    "action_items": [
        "The team needs to work on the project plan by the end of the week."
    ]
}
2025-03-25 02:21:51,287 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_0.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,302 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_1.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,315 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_2.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,328 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_3.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,341 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_4.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,353 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_5.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,365 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_6.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,377 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_7.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,391 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_8.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,402 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_9.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,414 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_10.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,426 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_11.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,437 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_12.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,449 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_13.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,460 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_14.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,473 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_15.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,485 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_16.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,496 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_17.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,508 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_18.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,520 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_19.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,532 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_20.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,544 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_21.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,556 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_22.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,567 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_23.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,578 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_24.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,593 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_25.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,604 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_26.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,617 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_27.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,628 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_28.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,641 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_29.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,693 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_30.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,716 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_31.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,740 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_32.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,755 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_33.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,769 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_34.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,780 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_35.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,791 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_36.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,803 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_37.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,815 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_38.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,826 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_39.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,842 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_40.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,853 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_41.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,864 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_42.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,876 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_43.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,887 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_44.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,899 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_45.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,910 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_46.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,924 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_47.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,935 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_48.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,946 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_49.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,958 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_50.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,969 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_51.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,980 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_52.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:51,992 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_53.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:52,003 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_54.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:52,014 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_55.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:52,026 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_56.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:52,038 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_57.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:52,050 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_58.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:52,061 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_59.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:52,073 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_60.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:52,085 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_61.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:52,096 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_62.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:52,102 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpalquuscw/chunk_63.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:21:52,107 - INFO - Transcription completed: 0 characters
2025-03-25 02:21:52,892 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-25 02:23:23,983 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_0.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:23,999 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_1.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,014 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_2.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,028 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_3.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,039 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_4.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,053 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_5.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,065 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_6.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,077 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_7.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,089 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_8.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,100 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_9.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,113 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_10.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,127 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_11.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,139 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_12.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,150 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_13.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,163 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_14.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,175 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_15.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,186 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_16.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,198 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_17.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,211 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_18.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,222 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_19.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,234 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_20.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,246 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_21.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,258 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_22.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,271 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_23.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,282 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_24.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,294 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_25.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,305 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_26.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,316 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_27.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,327 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_28.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,340 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_29.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,353 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_30.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,367 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_31.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,381 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_32.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,397 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_33.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,410 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_34.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,422 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_35.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,434 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_36.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,446 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_37.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,458 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_38.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,469 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_39.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,480 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_40.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,494 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_41.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,505 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_42.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,516 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_43.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,528 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_44.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,539 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_45.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,550 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_46.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,562 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_47.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,574 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_48.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,585 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_49.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,596 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_50.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,608 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_51.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,619 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_52.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,630 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_53.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,642 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_54.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,653 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_55.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,662 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_56.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,672 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_57.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,681 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_58.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,691 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_59.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,700 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_60.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,710 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_61.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,720 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_62.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,724 - ERROR - Error processing chunk /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/tmpfpa48b8a/chunk_63.wav: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:23:24,729 - INFO - Transcription completed: 0 characters
2025-03-25 02:23:25,330 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-25 02:28:06,491 - INFO - Audio preprocessed: annual meeting.wav.norm.wav
2025-03-25 02:28:06,495 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/annual meeting.wav.norm.wav
2025-03-25 02:28:07,993 - INFO - Audio duration: 630.82 seconds
2025-03-25 02:28:07,994 - INFO - Processing chunk 1
2025-03-25 02:28:08,068 - ERROR - Transcription error: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 4,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 452. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:34:36,340 - INFO - Audio preprocessed: annual meeting.wav.norm.wav
2025-03-25 02:34:36,344 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/annual meeting.wav.norm.wav
2025-03-25 02:34:37,948 - INFO - Audio duration: 630.82 seconds
2025-03-25 02:34:37,948 - INFO - Processing chunk 1
2025-03-25 02:35:13,754 - ERROR - Transcription error: WhisperForConditionalGeneration.forward() got an unexpected keyword argument 'input_ids'
2025-03-25 02:40:42,721 - INFO - Audio preprocessed: annual meeting.wav.norm.wav
2025-03-25 02:40:42,724 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/annual meeting.wav.norm.wav
2025-03-25 02:40:44,229 - INFO - Audio duration: 630.82 seconds
2025-03-25 02:40:44,230 - INFO - Processing chunk 1
2025-03-25 02:41:07,522 - ERROR - Transcription error: WhisperForConditionalGeneration.forward() got an unexpected keyword argument 'input_ids'
2025-03-25 02:43:33,521 - INFO - Audio preprocessed: annual meeting.wav.norm.wav
2025-03-25 02:43:33,524 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/annual meeting.wav.norm.wav
2025-03-25 02:43:35,006 - INFO - Audio duration: 630.82 seconds
2025-03-25 02:43:35,007 - INFO - Processing chunk 1
2025-03-25 02:43:56,761 - ERROR - Transcription error: WhisperForConditionalGeneration.forward() got an unexpected keyword argument 'input_ids'
2025-03-25 02:45:45,144 - INFO - Audio preprocessed: annual meeting.wav.norm.wav
2025-03-25 02:45:45,147 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/annual meeting.wav.norm.wav
2025-03-25 02:45:46,158 - ERROR - Transcription error: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 3,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 451. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
2025-03-25 02:48:33,620 - INFO - Audio preprocessed: annual meeting.wav.norm.wav
2025-03-25 02:48:33,623 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/annual meeting.wav.norm.wav
2025-03-25 02:49:38,846 - ERROR - Transcription error: WhisperForConditionalGeneration.forward() got an unexpected keyword argument 'input_ids'
2025-03-25 02:50:18,850 - INFO - Audio preprocessed: harvard.wav.norm.wav
2025-03-25 02:50:18,850 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/harvard.wav.norm.wav
2025-03-25 02:50:57,190 - ERROR - Transcription error: WhisperForConditionalGeneration.forward() got an unexpected keyword argument 'input_ids'
2025-03-25 15:21:45,852 - INFO - Audio preprocessed: harvard.wav.norm.wav
2025-03-25 15:21:45,854 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/harvard.wav.norm.wav
2025-03-25 15:22:35,259 - ERROR - Transcription error: WhisperForConditionalGeneration.forward() got an unexpected keyword argument 'input_ids'
2025-03-25 15:22:43,611 - INFO - Audio preprocessed: harvard.wav.norm.wav
2025-03-25 15:22:43,613 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/harvard.wav.norm.wav
2025-03-25 15:23:37,832 - ERROR - Transcription error: WhisperForConditionalGeneration.forward() got an unexpected keyword argument 'input_ids'
2025-03-25 15:47:38,223 - INFO - Audio preprocessed: harvard.wav.norm.wav
2025-03-25 15:47:38,223 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/harvard.wav.norm.wav
2025-03-25 15:47:51,676 - ERROR - Transcription error: WhisperForConditionalGeneration.forward() got an unexpected keyword argument 'input_ids'
2025-03-25 15:48:35,422 - INFO - Audio preprocessed: harvard.wav.norm.wav
2025-03-25 15:48:35,424 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/harvard.wav.norm.wav
2025-03-25 15:48:47,534 - ERROR - Transcription error: WhisperForConditionalGeneration.forward() got an unexpected keyword argument 'input_ids'
2025-03-25 15:50:49,877 - INFO - Audio preprocessed: harvard.wav.norm.wav
2025-03-25 15:50:49,877 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/harvard.wav.norm.wav
2025-03-25 15:51:02,040 - ERROR - Transcription error: WhisperForConditionalGeneration.forward() got an unexpected keyword argument 'input_ids'
2025-03-25 15:52:42,546 - INFO - Audio preprocessed: harvard.wav.norm.wav
2025-03-25 15:52:42,547 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/harvard.wav.norm.wav
2025-03-25 15:52:54,430 - ERROR - Transcription error: WhisperForConditionalGeneration.forward() got an unexpected keyword argument 'input_ids'
2025-03-25 16:07:04,260 - INFO - Audio preprocessed: harvard.wav.norm.wav
2025-03-25 16:07:04,261 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/harvard.wav.norm.wav
2025-03-25 16:07:12,240 - INFO - Transcription completed: 209 characters
2025-03-25 16:07:13,655 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-25 16:07:55,758 - INFO - Audio preprocessed: annual meeting.wav.norm.wav
2025-03-25 16:07:55,762 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/annual meeting.wav.norm.wav
2025-03-25 16:09:30,623 - INFO - Transcription completed: 7440 characters
2025-03-25 16:09:32,605 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-25 16:22:55,842 - INFO - Audio preprocessed: annual meeting.wav.norm.wav
2025-03-25 16:22:55,849 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/annual meeting.wav.norm.wav
2025-03-25 16:24:44,416 - INFO - Transcription completed: 7443 characters
2025-03-25 16:24:47,679 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-25 17:00:13,560 - INFO - Audio preprocessed: annual meeting.wav.norm.wav
2025-03-25 17:00:13,568 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/annual meeting.wav.norm.wav
2025-03-25 17:02:01,306 - INFO - Transcription completed: 7434 characters
2025-03-25 17:02:02,882 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-26 02:02:39,438 - ERROR - Form data requires "python-multipart" to be installed. 
You can install "python-multipart" with: 

pip install python-multipart

2025-03-26 02:19:34,947 - INFO - Use pytorch device_name: mps
2025-03-26 02:19:34,947 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:20:26,945 - INFO - Use pytorch device_name: mps
2025-03-26 02:20:26,946 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:21:25,528 - INFO - Use pytorch device_name: mps
2025-03-26 02:21:25,533 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:21:44,208 - ERROR - Error loading meeting data: Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version).
2025-03-26 02:21:44,208 - ERROR - Error answering question: Meeting data not found for ID: annual meeting
2025-03-26 02:22:51,543 - ERROR - Error loading meeting data: 'participants'
2025-03-26 02:22:51,543 - ERROR - Error answering question: Meeting data not found for ID: annual meeting_20250325_160932
2025-03-26 02:24:11,733 - INFO - Use pytorch device_name: mps
2025-03-26 02:24:11,734 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:24:51,026 - INFO - Use pytorch device_name: mps
2025-03-26 02:24:51,028 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:25:06,188 - INFO - Loading meeting data from: annual meeting_20250325_160932.json
2025-03-26 02:25:06,190 - ERROR - Error loading meeting data: 'participants'
2025-03-26 02:25:06,190 - ERROR - Error answering question: Meeting data not found for ID: annual meeting_20250325_160932
2025-03-26 02:25:18,301 - INFO - Loading meeting data from: annual meeting_20250325_160932.json
2025-03-26 02:25:18,302 - ERROR - Error loading meeting data: 'participants'
2025-03-26 02:25:18,302 - ERROR - Error answering question: Meeting data not found for ID: annual meeting_20250325_160932
2025-03-26 02:25:37,324 - INFO - Loading meeting data from: annual meeting_20250325_170202.json
2025-03-26 02:25:38,492 - ERROR - Error loading meeting data: Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version).
2025-03-26 02:25:38,492 - ERROR - Error answering question: Meeting data not found for ID: annual meeting
2025-03-26 02:28:31,083 - INFO - Use pytorch device_name: mps
2025-03-26 02:28:31,083 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:29:14,448 - INFO - Use pytorch device_name: mps
2025-03-26 02:29:14,450 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:29:28,353 - INFO - Available files: ['harvard_20250325_160713.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-26 02:29:28,354 - INFO - Loading meeting data from: annual meeting_20250325_170202.json
2025-03-26 02:29:29,064 - ERROR - Error loading meeting data: Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version).
2025-03-26 02:29:29,064 - ERROR - Error answering question: Meeting data not found for ID: annual meeting
2025-03-26 02:30:13,450 - INFO - Use pytorch device_name: mps
2025-03-26 02:30:13,451 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:30:46,865 - INFO - Use pytorch device_name: mps
2025-03-26 02:30:46,868 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:31:35,740 - INFO - Available files: ['harvard_20250325_160713.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-26 02:31:35,741 - INFO - Loading meeting data from: annual meeting_20250325_170202.json
2025-03-26 02:31:36,309 - ERROR - Error loading meeting data: Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version).
2025-03-26 02:31:36,310 - ERROR - Error answering question: Meeting data not found for ID: annual meeting_20250325_170202
2025-03-26 02:33:15,761 - INFO - Available files: ['harvard_20250325_160713.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-26 02:33:15,762 - INFO - Loading meeting data from: annual meeting_20250325_170202.json
2025-03-26 02:33:16,129 - INFO - Loading faiss.
2025-03-26 02:33:17,308 - INFO - Successfully loaded faiss.
2025-03-26 02:33:17,312 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes.
2025-03-26 02:33:17,320 - INFO - Successfully loaded meeting data for ID: annual meeting_20250325_170202
2025-03-26 02:33:17,335 - ERROR - Error answering question: 2 validation errors for LLMChain
llm.is-instance[Runnable]
  Input should be an instance of Runnable [type=is_instance_of, input_value=<groq.Groq object at 0x3dcfbba50>, input_type=Groq]
    For further information visit https://errors.pydantic.dev/2.10/v/is_instance_of
llm.is-instance[Runnable]
  Input should be an instance of Runnable [type=is_instance_of, input_value=<groq.Groq object at 0x3dcfbba50>, input_type=Groq]
    For further information visit https://errors.pydantic.dev/2.10/v/is_instance_of
2025-03-26 02:39:54,171 - INFO - Use pytorch device_name: mps
2025-03-26 02:39:54,171 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:40:53,941 - INFO - Use pytorch device_name: mps
2025-03-26 02:40:53,943 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:41:45,539 - INFO - Use pytorch device_name: mps
2025-03-26 02:41:45,539 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:42:34,586 - INFO - Use pytorch device_name: mps
2025-03-26 02:42:34,588 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:43:03,276 - INFO - Available files: ['harvard_20250325_160713.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-26 02:43:03,276 - ERROR - No meeting data found for ID: annual_meeting
2025-03-26 02:43:03,276 - ERROR - Tried patterns: ['annual_meeting', 'annual_meeting', 'annual_meeting', 'annual_meeting']
2025-03-26 02:43:03,276 - ERROR - Error answering question: Meeting data not found for ID: annual_meeting
2025-03-26 02:43:24,857 - INFO - Available files: ['harvard_20250325_160713.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-26 02:43:24,858 - INFO - Loading meeting data from: annual meeting_20250325_170202.json
2025-03-26 02:43:25,625 - INFO - Loading faiss.
2025-03-26 02:43:25,922 - INFO - Successfully loaded faiss.
2025-03-26 02:43:25,930 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes.
2025-03-26 02:43:25,949 - INFO - Successfully loaded meeting data for ID: annual meeting_20250325_170202
2025-03-26 02:43:25,963 - ERROR - Error answering question: 1 validation error for StuffDocumentsChain
  Value error, document_variable_name context was not found in llm_chain input_variables: ['question'] [type=value_error, input_value={'llm_chain': LLMChain(ve...None, 'callbacks': None}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/value_error
2025-03-26 02:46:19,249 - INFO - Use pytorch device_name: mps
2025-03-26 02:46:19,249 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:47:15,919 - INFO - Use pytorch device_name: mps
2025-03-26 02:47:15,921 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:48:24,500 - INFO - Use pytorch device_name: mps
2025-03-26 02:48:24,500 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:49:07,757 - INFO - Use pytorch device_name: mps
2025-03-26 02:49:07,757 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:49:59,965 - INFO - Use pytorch device_name: mps
2025-03-26 02:49:59,968 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 02:50:12,257 - INFO - Available files: ['harvard_20250325_160713.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-26 02:50:12,258 - INFO - Loading meeting data from: annual meeting_20250325_170202.json
2025-03-26 02:50:13,597 - INFO - Loading faiss.
2025-03-26 02:50:14,446 - INFO - Successfully loaded faiss.
2025-03-26 02:50:14,467 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes.
2025-03-26 02:50:14,510 - INFO - Successfully loaded meeting data for ID: annual meeting_20250325_170202
2025-03-26 02:50:16,780 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-03-26 02:50:16,783 - ERROR - Error answering question: Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-03-26 02:53:10,929 - INFO - CUDA not available - using CPU FAISS
2025-03-26 02:57:24,804 - INFO - CUDA not available - using CPU FAISS
2025-03-26 02:59:47,013 - INFO - Using device: cpu for embeddings
2025-03-26 02:59:47,212 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:00:31,251 - INFO - Using device: cpu for embeddings
2025-03-26 03:00:31,271 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:01:13,710 - INFO - Available files: ['harvard_20250325_160713.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-26 03:01:13,711 - INFO - Loading meeting data from: annual meeting_20250325_170202.json
2025-03-26 03:01:13,982 - ERROR - Error loading meeting data: 'MeetingRAG' object has no attribute 'use_gpu'
2025-03-26 03:01:13,983 - ERROR - Error answering question: Meeting data not found for ID: annual meeting_20250325_170202
2025-03-26 03:01:56,734 - INFO - Available files: ['harvard_20250325_160713.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-26 03:01:56,734 - INFO - Loading meeting data from: annual meeting_20250325_170202.json
2025-03-26 03:01:56,807 - ERROR - Error loading meeting data: 'MeetingRAG' object has no attribute 'use_gpu'
2025-03-26 03:01:56,807 - ERROR - Error answering question: Meeting data not found for ID: annual meeting
2025-03-26 03:02:29,587 - INFO - Available files: ['harvard_20250325_160713.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-26 03:02:29,587 - INFO - Loading meeting data from: annual meeting_20250325_170202.json
2025-03-26 03:02:29,648 - ERROR - Error loading meeting data: 'MeetingRAG' object has no attribute 'use_gpu'
2025-03-26 03:02:29,648 - ERROR - Error answering question: Meeting data not found for ID: annual meeting_20250325_170202
2025-03-26 03:04:07,833 - ERROR - Error during cleanup: 'MeetingRAG' object has no attribute 'use_gpu'
2025-03-26 03:04:54,728 - INFO - Using device: cpu for embeddings
2025-03-26 03:04:54,922 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:05:51,837 - INFO - Using device: cpu for embeddings
2025-03-26 03:05:51,889 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:06:02,332 - INFO - Available files: ['harvard_20250325_160713.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-26 03:06:02,334 - INFO - Loading meeting data from: annual meeting_20250325_170202.json
2025-03-26 03:06:02,722 - INFO - Successfully loaded meeting data for ID: annual meeting_20250325_170202
2025-03-26 03:06:04,019 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-26 03:06:04,101 - ERROR - Error answering question: Got multiple output keys: dict_keys(['answer', 'source_documents']), cannot determine which to store in memory. Please set the 'output_key' explicitly.
2025-03-26 03:08:23,377 - INFO - Using device: cpu for embeddings
2025-03-26 03:08:23,567 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:08:56,272 - INFO - Using device: cpu for embeddings
2025-03-26 03:08:56,320 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:09:09,807 - INFO - Available files: ['harvard_20250325_160713.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-26 03:09:09,810 - INFO - Loading meeting data from: annual meeting_20250325_170202.json
2025-03-26 03:09:10,968 - INFO - Successfully loaded meeting data for ID: annual meeting_20250325_170202
2025-03-26 03:09:13,218 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-26 03:09:13,268 - INFO - Question answered for meeting annual meeting_20250325_170202: What were the key decisions made in this meeting?...
2025-03-26 03:11:34,520 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-26 03:11:35,337 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-26 03:11:35,339 - INFO - Question answered for meeting annual meeting_20250325_170202: who is Mr. Kim Lambert?...
2025-03-26 03:13:16,326 - INFO - Using device: cpu for embeddings
2025-03-26 03:13:16,504 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:13:52,378 - INFO - Using device: cpu for embeddings
2025-03-26 03:13:52,427 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:17:32,192 - INFO - Using device: cpu for embeddings
2025-03-26 03:17:32,368 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:18:08,259 - INFO - Using device: cpu for embeddings
2025-03-26 03:18:08,309 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:20:09,242 - INFO - Audio preprocessed: annual meeting.wav.norm.wav
2025-03-26 03:20:09,245 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/annual meeting.wav.norm.wav
2025-03-26 03:21:47,711 - INFO - Transcription completed: 7441 characters
2025-03-26 03:21:49,439 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-26 03:24:14,490 - INFO - Using device: cpu for embeddings
2025-03-26 03:24:14,675 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:25:06,074 - INFO - Using device: cpu for embeddings
2025-03-26 03:25:06,124 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:27:43,910 - INFO - Using device: cpu for embeddings
2025-03-26 03:27:44,106 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:28:27,843 - INFO - Using device: cpu for embeddings
2025-03-26 03:28:27,891 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:29:14,833 - INFO - Available files: ['harvard_20250325_160713.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'annual meeting_20250326_032149.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-26 03:29:14,833 - INFO - Loading meeting data from: annual meeting_20250326_032149.json
2025-03-26 03:29:15,286 - INFO - Successfully loaded meeting data for ID: annual meeting_20250326_032149
2025-03-26 03:29:16,317 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-26 03:29:16,329 - INFO - Question answered for meeting annual meeting_20250326_032149: What were the key decisions made in this meeting?...
2025-03-26 03:30:18,565 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-26 03:30:19,114 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-26 03:30:19,116 - INFO - Question answered for meeting annual meeting_20250326_032149: Who is  Mr. Morale?...
2025-03-26 03:32:44,458 - INFO - Using device: cpu for embeddings
2025-03-26 03:32:44,640 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-26 03:33:26,746 - INFO - Using device: cpu for embeddings
2025-03-26 03:33:26,797 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 15:36:24,051 - INFO - Using device: cpu for embeddings
2025-03-27 15:36:24,370 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 15:37:35,022 - INFO - Using device: cpu for embeddings
2025-03-27 15:37:35,195 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 15:38:56,673 - INFO - Using device: cpu for embeddings
2025-03-27 15:38:56,725 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 15:47:18,722 - INFO - Using device: cpu for embeddings
2025-03-27 15:47:18,961 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 15:48:16,651 - INFO - Using device: cpu for embeddings
2025-03-27 15:48:16,722 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 15:49:10,738 - INFO - Audio preprocessed: lemonmeet.wav.norm.wav
2025-03-27 15:49:10,741 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/lemonmeet.wav.norm.wav
2025-03-27 15:51:23,248 - INFO - Transcription completed: 7434 characters
2025-03-27 15:51:25,082 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-27 15:54:03,344 - INFO - Using device: cpu for embeddings
2025-03-27 15:54:03,671 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 15:55:22,766 - INFO - Using device: cpu for embeddings
2025-03-27 15:55:22,881 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 15:56:55,347 - INFO - Audio preprocessed: lemonmeet.wav.norm.wav
2025-03-27 15:56:55,351 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/lemonmeet.wav.norm.wav
2025-03-27 15:59:07,968 - INFO - Transcription completed: 7434 characters
2025-03-27 15:59:09,986 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-27 16:02:14,391 - INFO - Using device: cpu for embeddings
2025-03-27 16:02:14,616 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 16:02:57,436 - INFO - Using device: cpu for embeddings
2025-03-27 16:02:57,486 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 16:05:17,719 - INFO - Audio preprocessed: lemonmeet.wav.norm.wav
2025-03-27 16:05:17,722 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/lemonmeet.wav.norm.wav
2025-03-27 16:07:25,573 - INFO - Transcription completed: 7434 characters
2025-03-27 16:07:28,884 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-27 16:09:11,553 - INFO - Audio preprocessed: lemonmeet.wav.norm.wav
2025-03-27 16:09:11,556 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/lemonmeet.wav.norm.wav
2025-03-27 16:10:51,789 - INFO - Transcription completed: 7439 characters
2025-03-27 16:11:00,970 - INFO - Retrying request to /openai/v1/chat/completions in 0.426343 seconds
2025-03-27 16:11:11,407 - INFO - Retrying request to /openai/v1/chat/completions in 0.771275 seconds
2025-03-27 16:11:36,411 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-27 16:15:56,165 - INFO - Using device: cpu for embeddings
2025-03-27 16:15:56,365 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 16:16:36,670 - INFO - Using device: cpu for embeddings
2025-03-27 16:16:36,729 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 16:17:44,021 - INFO - Audio preprocessed: lemonmeet.wav.norm.wav
2025-03-27 16:17:44,026 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/lemonmeet.wav.norm.wav
2025-03-27 16:19:28,598 - INFO - Transcription completed: 7445 characters
2025-03-27 16:19:31,293 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-27 16:30:48,099 - INFO - Available files: ['harvard_20250325_160713.json', 'lemonmeet_20250327_161931.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'annual meeting_20250326_032149.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-27 16:30:48,102 - INFO - Loading meeting data from: lemonmeet_20250327_161931.json
2025-03-27 16:30:48,677 - INFO - Successfully loaded meeting data for ID: lemonmeet
2025-03-27 16:30:49,864 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-27 16:30:49,875 - INFO - Question answered for meeting lemonmeet: what is it all about...
2025-03-27 16:34:46,392 - INFO - Using device: cpu for embeddings
2025-03-27 16:34:46,616 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 16:35:22,663 - INFO - Using device: cpu for embeddings
2025-03-27 16:35:22,707 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-27 16:37:17,621 - INFO - Available files: ['harvard_20250325_160713.json', 'lemonmeet_20250327_161931.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'annual meeting_20250326_032149.json', 'harvard_20250317_150641.json', 'annual meeting_20250325_170202.json']
2025-03-27 16:37:17,622 - INFO - Loading meeting data from: lemonmeet_20250327_161931.json
2025-03-27 16:37:18,225 - INFO - Successfully loaded meeting data for ID: lemonmeet
2025-03-27 16:37:19,375 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-27 16:37:19,402 - INFO - Question answered for meeting lemonmeet: what is it all about...
2025-03-27 16:37:38,292 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-27 16:37:39,083 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-27 16:37:39,084 - INFO - Question answered for meeting lemonmeet: who all have attended this meeting...
2025-03-27 16:37:49,162 - INFO - Cleared conversation history for meeting: lemonmeet
2025-03-27 16:37:56,620 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-27 16:37:56,621 - INFO - Question answered for meeting lemonmeet: who all have attended this meeting...
2025-03-27 16:38:22,182 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-27 16:38:22,768 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-27 16:38:22,770 - INFO - Question answered for meeting lemonmeet: who is Bunkum...
2025-03-28 01:26:18,967 - INFO - Using device: cpu for embeddings
2025-03-28 01:26:19,186 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 01:27:17,936 - INFO - Using device: cpu for embeddings
2025-03-28 01:27:18,144 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 01:28:24,575 - INFO - Using device: cpu for embeddings
2025-03-28 01:28:24,644 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:26:12,361 - INFO - Using device: cpu for embeddings
2025-03-28 14:26:12,560 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:27:12,760 - INFO - Using device: cpu for embeddings
2025-03-28 14:27:12,947 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:28:23,445 - INFO - Using device: cpu for embeddings
2025-03-28 14:28:23,502 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:33:38,029 - INFO - Using device: cpu for embeddings
2025-03-28 14:33:39,125 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:35:36,563 - INFO - Using device: cpu for embeddings
2025-03-28 14:35:37,141 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:37:36,229 - INFO - Using device: cpu for embeddings
2025-03-28 14:37:36,422 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:38:10,225 - INFO - Using device: cpu for embeddings
2025-03-28 14:38:10,277 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:38:45,504 - INFO - Using device: cpu for embeddings
2025-03-28 14:38:45,705 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:39:24,976 - INFO - Using device: cpu for embeddings
2025-03-28 14:39:25,029 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:40:12,252 - INFO - Using device: cpu for embeddings
2025-03-28 14:40:12,854 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:42:47,927 - INFO - Using device: cpu for embeddings
2025-03-28 14:42:48,642 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:43:52,865 - INFO - Using device: cpu for embeddings
2025-03-28 14:43:53,428 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:50:26,634 - INFO - Using device: cpu for embeddings
2025-03-28 14:50:26,854 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:51:09,304 - INFO - Using device: cpu for embeddings
2025-03-28 14:51:09,488 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:51:40,591 - INFO - Using device: cpu for embeddings
2025-03-28 14:51:40,651 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-03-28 14:52:07,824 - INFO - Audio preprocessed: lemonmeet.wav.norm.wav
2025-03-28 14:52:07,827 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/lemonmeet.wav.norm.wav
2025-03-28 14:54:03,544 - INFO - Transcription completed: 7443 characters
2025-03-28 14:54:06,600 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-28 15:08:33,525 - INFO - Available files: ['harvard_20250325_160713.json', 'lemonmeet_20250327_161931.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'annual meeting_20250326_032149.json', 'harvard_20250317_150641.json', 'lemonmeet_20250328_145406.json', 'annual meeting_20250325_170202.json']
2025-03-28 15:08:33,527 - INFO - Loading meeting data from: harvard_20250325_160713.json
2025-03-28 15:08:33,533 - ERROR - Error loading meeting data: 'participants'
2025-03-28 15:08:33,533 - ERROR - Error answering question: Meeting data not found for ID: harvard
2025-04-24 00:12:08,173 - INFO - Using device: cpu for embeddings
2025-04-24 00:12:08,384 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-04-24 00:12:45,784 - INFO - Using device: cpu for embeddings
2025-04-24 00:12:45,972 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-04-24 00:13:25,912 - INFO - Using device: cpu for embeddings
2025-04-24 00:13:25,961 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-04-24 00:13:59,585 - INFO - Audio preprocessed: lemonmeet.wav.norm.wav
2025-04-24 00:13:59,588 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/lemonmeet.wav.norm.wav
2025-04-24 00:15:58,609 - INFO - Transcription completed: 7445 characters
2025-04-24 00:16:01,432 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-24 00:16:53,446 - INFO - Available files: ['harvard_20250325_160713.json', 'lemonmeet_20250327_161931.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'annual meeting_20250326_032149.json', 'harvard_20250317_150641.json', 'lemonmeet_20250328_145406.json', 'lemonmeet_20250424_001601.json', 'annual meeting_20250325_170202.json']
2025-04-24 00:16:53,446 - INFO - Loading meeting data from: lemonmeet_20250424_001601.json
2025-04-24 00:16:53,995 - INFO - Successfully loaded meeting data for ID: lemonmeet
2025-04-24 00:16:54,987 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-24 00:16:54,994 - INFO - Question answered for meeting lemonmeet: what's happening...
2025-04-24 00:17:01,238 - INFO - Cleared conversation history for meeting: lemonmeet
2025-04-24 00:17:19,294 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-24 00:17:19,296 - INFO - Question answered for meeting lemonmeet: who all are present...
2025-04-24 11:22:21,597 - INFO - Using device: cpu for embeddings
2025-04-24 11:22:21,756 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-04-24 11:23:21,563 - INFO - Using device: cpu for embeddings
2025-04-24 11:23:21,760 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-04-24 11:24:14,099 - INFO - Using device: cpu for embeddings
2025-04-24 11:24:14,166 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-04-24 11:27:27,875 - INFO - Audio preprocessed: lemonmeet.wav.norm.wav
2025-04-24 11:27:27,878 - INFO - Processing audio file: /var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/lemonmeet.wav.norm.wav
2025-04-24 11:29:11,197 - INFO - Transcription completed: 7439 characters
2025-04-24 11:29:17,424 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-24 11:30:13,537 - INFO - Available files: ['lemonmeet_20250424_112917.json', 'harvard_20250325_160713.json', 'lemonmeet_20250327_161931.json', 'transcript_analysis_20250224_151506.json', 'transcript_analysis_20250224_151841.json', 'annual meeting_20250326_032149.json', 'harvard_20250317_150641.json', 'lemonmeet_20250328_145406.json', 'lemonmeet_20250424_001601.json', 'annual meeting_20250325_170202.json']
2025-04-24 11:30:13,538 - INFO - Loading meeting data from: lemonmeet_20250424_112917.json
2025-04-24 11:30:14,047 - INFO - Successfully loaded meeting data for ID: lemonmeet
2025-04-24 11:30:15,832 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-24 11:30:15,853 - INFO - Question answered for meeting lemonmeet: what is it all about...
2025-04-24 11:30:29,305 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-24 11:30:30,738 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-24 11:30:30,745 - INFO - Question answered for meeting lemonmeet: who alll are present...
2025-04-24 11:30:37,033 - INFO - Cleared conversation history for meeting: lemonmeet
